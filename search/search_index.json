{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Mobility Database API Client","text":"<p>A Python client for downloading GTFS files through the Mobility Database API.</p> <p> </p>"},{"location":"#features","title":"Features","text":"<ul> <li>Search for GTFS providers by country or name</li> <li>Download GTFS datasets from hosted or direct sources</li> <li>Track dataset metadata and changes</li> <li>Thread-safe and process-safe operations</li> <li>Automatic token refresh and error handling</li> </ul>"},{"location":"#installation","title":"Installation","text":"<pre><code>pip install mobility-db-api\n</code></pre>"},{"location":"#quick-example","title":"Quick Example","text":"<pre><code>from mobility_db_api import MobilityAPI\n\n# Initialize client (uses MOBILITY_API_REFRESH_TOKEN env var)\napi = MobilityAPI()\n\n# Search for providers in Belgium\nproviders = api.get_providers_by_country(\"BE\")\nprint(f\"Found {len(providers)} providers\")\n\n# Download a dataset\nif providers:\n    dataset_path = api.download_latest_dataset(providers[0]['id'])\n    print(f\"Dataset downloaded to: {dataset_path}\")\n</code></pre>"},{"location":"#documentation","title":"Documentation","text":"<ul> <li>Quick Start Guide - Get up and running in minutes</li> <li>Examples - Common use cases and patterns</li> <li>API Reference - Detailed API documentation</li> <li>Contributing - Help improve the client</li> <li>Changelog - Latest changes and updates </li> </ul>"},{"location":"changelog/","title":"Changelog","text":"<p>All notable changes to this project will be documented in this file.</p> <p>The format is based on Keep a Changelog, and this project adheres to Semantic Versioning.</p>"},{"location":"changelog/#unreleased","title":"Unreleased","text":""},{"location":"changelog/#added","title":"Added","text":"<ul> <li>Thread-safe and process-safe metadata handling:</li> <li>File locking for concurrent metadata access</li> <li>Shared locks for reading (multiple readers allowed)</li> <li>Exclusive locks for writing (one writer at a time)</li> <li>Automatic metadata merging for concurrent writes</li> <li>Metadata change detection:</li> <li>Automatic detection of external changes to metadata file</li> <li><code>reload_metadata()</code> method to manually reload metadata</li> <li><code>ensure_metadata_current()</code> method to check and reload if needed</li> <li>Improved error handling:</li> <li>Graceful handling of corrupted metadata files</li> <li>Proper cleanup of file locks</li> <li>Informative error logging</li> </ul>"},{"location":"changelog/#changed","title":"Changed","text":"<ul> <li>Made API instances fully independent:</li> <li>Each instance can have its own data directory</li> <li>Separate logger instances for better debugging</li> <li>Safe concurrent access to shared data directories</li> </ul>"},{"location":"changelog/#020-2024-12-23","title":"[0.2.0] - 2024-12-23","text":""},{"location":"changelog/#added_1","title":"Added","text":"<ul> <li>New bulk deletion methods:</li> <li><code>delete_provider_datasets()</code>: Delete all datasets for a specific provider</li> <li><code>delete_all_datasets()</code>: Delete all downloaded datasets across all providers</li> <li>Smart directory cleanup:</li> <li>Automatic removal of empty provider directories</li> <li>Preservation of custom files and directories</li> <li>Safe cleanup that only removes dataset-related content</li> </ul>"},{"location":"changelog/#changed_1","title":"Changed","text":"<ul> <li>Enhanced <code>delete_dataset()</code> method to handle provider directory cleanup</li> <li>Improved logging for deletion operations</li> </ul>"},{"location":"changelog/#developer-changes","title":"Developer Changes","text":"<ul> <li>Added comprehensive tests for directory cleanup behavior</li> <li>Added tests for bulk deletion operations</li> <li>Updated documentation with new deletion methods and examples</li> </ul>"},{"location":"changelog/#011-initial-release-2024-12-22","title":"[0.1.1] - Initial Release - 2024-12-22","text":""},{"location":"changelog/#added_2","title":"Added","text":"<ul> <li>Basic GTFS Schedule dataset management functionality</li> <li>Provider search by country and name</li> <li>Dataset download and extraction</li> <li>Metadata tracking</li> <li>Environment variable support</li> <li>Progress tracking for downloads</li> <li>Feed validity period detection </li> </ul>"},{"location":"contributing/","title":"Contributing","text":""},{"location":"contributing/#development-setup","title":"Development Setup","text":"<pre><code># Clone repository\ngit clone https://github.com/bdamokos/mobility-db-api.git\ncd mobility-db-api\n\n# Create virtual environment\npython -m venv venv\nsource venv/bin/activate  # On Windows: venv\\Scripts\\activate\n\n# Install development dependencies\npip install -e \".[dev]\"\n</code></pre>"},{"location":"contributing/#running-tests","title":"Running Tests","text":"<pre><code># Run all tests\npytest\n\n# Run with coverage\npytest --cov=mobility_db_api\n</code></pre>"},{"location":"contributing/#documentation","title":"Documentation","text":"<pre><code># Install documentation dependencies\npip install -e \".[docs]\"\n\n# Start documentation server\nmkdocs serve\n</code></pre>"},{"location":"contributing/#pull-request-process","title":"Pull Request Process","text":"<ol> <li>Fork the repository</li> <li>Create a feature branch</li> <li>Make your changes</li> <li>Run tests and update documentation</li> <li>Submit pull request</li> </ol>"},{"location":"contributing/#commit-messages","title":"Commit Messages","text":"<p>Follow the conventional commits specification:</p> <pre><code>type(scope): description\n\n[optional body]\n</code></pre> <p>Types: - <code>feat</code>: New feature - <code>fix</code>: Bug fix - <code>docs</code>: Documentation changes - <code>test</code>: Adding/updating tests - <code>refactor</code>: Code refactoring</p> <p>Example: <pre><code>feat(client): add support for direct downloads\n\n- Add direct_download parameter\n- Update documentation\n- Add tests\n</code></pre></p>"},{"location":"contributing/#release-process","title":"Release Process","text":"<ol> <li>Update version in <code>pyproject.toml</code></li> <li>Update the changelog</li> <li>Create release commit</li> <li>Create GitHub release</li> <li>GitHub Actions will publish to PyPI </li> </ol>"},{"location":"examples/","title":"Examples","text":""},{"location":"examples/#provider-search","title":"Provider Search","text":"<pre><code>from mobility_db_api import MobilityAPI\n\napi = MobilityAPI()\n\n# Search by country\nproviders = api.get_providers_by_country(\"BE\")\nprint(f\"Found {len(providers)} providers in Belgium\")\n\n# Search by name\nsncb = api.get_providers_by_name(\"SNCB\")\nprint(f\"Found {len(sncb)} SNCB providers\")\n\n# Print provider details\nif providers:\n    provider = providers[0]\n    print(f\"Provider: {provider['provider']}\")\n    print(f\"ID: {provider['id']}\")\n    print(f\"Direct download: {'Yes' if provider.get('direct_download_url') else 'No'}\")\n</code></pre>"},{"location":"examples/#dataset-download","title":"Dataset Download","text":"<pre><code>from mobility_db_api import MobilityAPI\nfrom pathlib import Path\n\napi = MobilityAPI()\n\n# Download to default location\ndataset_path = api.download_latest_dataset(\"tld-5862\")  # Vol\u00e1nbusz ID\nprint(f\"Dataset downloaded to: {dataset_path}\")\n\n# Download to custom directory with direct source\ndataset_path = api.download_latest_dataset(\n    provider_id=\"tld-5862\",\n    download_dir=\"custom_downloads\",\n    use_direct_source=True\n)\n</code></pre>"},{"location":"examples/#metadata-management","title":"Metadata Management","text":"<pre><code>from mobility_db_api import MobilityAPI\nfrom pathlib import Path\nimport json\n\napi = MobilityAPI()\n\n# Read metadata\nmetadata_file = Path('downloads/datasets_metadata.json')\nif metadata_file.exists():\n    with open(metadata_file) as f:\n        metadata = json.load(f)\n        for dataset_id, info in metadata.items():\n            print(f\"\\nDataset: {dataset_id}\")\n            print(f\"Provider: {info['provider_name']}\")\n            print(f\"Downloaded: {info['download_date']}\")\n</code></pre>"},{"location":"examples/#concurrent-downloads","title":"Concurrent Downloads","text":"<pre><code>from mobility_db_api import MobilityAPI\nfrom concurrent.futures import ThreadPoolExecutor\n\ndef download_dataset(provider_id: str) -&gt; str:\n    \"\"\"Download dataset in a separate thread\"\"\"\n    api = MobilityAPI()  # Each thread gets its own instance\n    try:\n        path = api.download_latest_dataset(provider_id)\n        return f\"Successfully downloaded to {path}\"\n    except Exception as e:\n        return f\"Failed to download: {e}\"\n\n# Download multiple datasets concurrently\napi = MobilityAPI()\nproviders = api.get_providers_by_country(\"BE\")\nprovider_ids = [p['id'] for p in providers[:3]]  # First 3 providers\n\nwith ThreadPoolExecutor(max_workers=3) as executor:\n    results = list(executor.map(download_dataset, provider_ids))\n\nfor result in results:\n    print(result)\n</code></pre>"},{"location":"examples/#error-handling","title":"Error Handling","text":"<pre><code>from mobility_db_api import MobilityAPI\nfrom mobility_db_api.exceptions import (\n    AuthenticationError,\n    DownloadError,\n    MetadataError\n)\n\napi = MobilityAPI()\n\ntry:\n    dataset_path = api.download_latest_dataset(\"invalid-id\")\nexcept AuthenticationError:\n    print(\"Check your API token\")\nexcept DownloadError as e:\n    print(f\"Download failed: {e}\")\nexcept MetadataError as e:\n    print(f\"Metadata error: {e}\")\n</code></pre>"},{"location":"quickstart/","title":"Quick Start","text":""},{"location":"quickstart/#installation","title":"Installation","text":"<pre><code>pip install mobility-db-api\n</code></pre>"},{"location":"quickstart/#authentication","title":"Authentication","text":"<ol> <li>Get your API token from the Mobility Database</li> <li>Set it as an environment variable:    <pre><code>export MOBILITY_API_REFRESH_TOKEN=your_token_here\n</code></pre></li> </ol> <p>Or create a <code>.env</code> file in your project directory:    <pre><code># .env\nMOBILITY_API_REFRESH_TOKEN=your_token_here\n</code></pre></p> <p>The client will automatically load the token from either source.</p>"},{"location":"quickstart/#basic-usage","title":"Basic Usage","text":"<pre><code>from mobility_db_api import MobilityAPI\n\n# Initialize client (uses environment variable or .env file for token)\napi = MobilityAPI()\n\n# Search for providers\nproviders = api.get_providers_by_country(\"BE\")\nprint(f\"Found {len(providers)} providers\")\n\n# Download a dataset\nif providers:\n    dataset_path = api.download_latest_dataset(\n        providers[0]['id'],\n        download_dir='downloads'\n    )\n    print(f\"Dataset downloaded to: {dataset_path}\")\n</code></pre>"},{"location":"quickstart/#whats-next","title":"What's Next?","text":"<ul> <li>Check the examples for common use cases</li> <li>Read the API reference for detailed documentation</li> <li>See the contributing guide if you want to help improve the client </li> </ul>"},{"location":"api-reference/client/","title":"API Reference: Client","text":""},{"location":"api-reference/client/#mobility_db_api.api.MobilityAPI","title":"<code>mobility_db_api.api.MobilityAPI(data_dir='data', refresh_token=None, log_level='INFO', logger_name='mobility_db_api')</code>","text":"<p>A client for interacting with the Mobility Database API.</p> <p>This class provides methods to search for GTFS providers, download datasets, and manage downloaded data. It handles authentication, caching, and metadata tracking automatically.</p> <p>Attributes:</p> Name Type Description <code>data_dir</code> <code>Path</code> <p>Directory where downloaded datasets are stored</p> <code>refresh_token</code> <code>str</code> <p>Token used for API authentication</p> <code>datasets</code> <code>Dict</code> <p>Dictionary of downloaded dataset metadata</p> Example <p>api = MobilityAPI(data_dir=\"data/provider1\") providers = api.get_providers_by_country(\"HU\") dataset_path = api.download_latest_dataset(\"tld-5862\")</p> <p>Initialize the API client.</p> <p>Parameters:</p> Name Type Description Default <code>data_dir</code> <code>str</code> <p>Base directory for all GTFS downloads</p> <code>'data'</code> <code>refresh_token</code> <code>Optional[str]</code> <p>Optional refresh token. If not provided, will try to load from .env file</p> <code>None</code> <code>log_level</code> <code>str</code> <p>Logging level (DEBUG, INFO, WARNING, ERROR). Defaults to INFO.</p> <code>'INFO'</code> <code>logger_name</code> <code>str</code> <p>Name for the logger instance. Defaults to 'mobility_db_api'.         Consider using a unique name per instance if running multiple instances.</p> <code>'mobility_db_api'</code> Source code in <code>src/mobility_db_api/api.py</code> <pre><code>def __init__(self, data_dir: str = \"data\", refresh_token: Optional[str] = None,\n             log_level: str = \"INFO\", logger_name: str = \"mobility_db_api\"):\n    \"\"\"\n    Initialize the API client.\n\n    Args:\n        data_dir: Base directory for all GTFS downloads\n        refresh_token: Optional refresh token. If not provided, will try to load from .env file\n        log_level: Logging level (DEBUG, INFO, WARNING, ERROR). Defaults to INFO.\n        logger_name: Name for the logger instance. Defaults to 'mobility_db_api'.\n                    Consider using a unique name per instance if running multiple instances.\n    \"\"\"\n    # Set up logger with instance-specific name if needed\n    self.logger = setup_logger(name=f\"{logger_name}_{data_dir}\", level=log_level)\n    self.logger.debug(\"Initializing MobilityAPI client\")\n\n    self.base_url = \"https://api.mobilitydatabase.org/v1\"\n    self.data_dir = Path(data_dir)\n    self.data_dir.mkdir(parents=True, exist_ok=True)\n    self.metadata_file = self.data_dir / \"datasets_metadata.json\"\n    self.refresh_token = refresh_token\n    self._last_metadata_mtime = None\n    self._load_metadata()\n\n    self.logger.info(f\"Initialized client with data directory: {self.data_dir}\")\n</code></pre>"},{"location":"api-reference/client/#mobility_db_api.api.MobilityAPI--can-create-another-instance-with-different-configuration","title":"Can create another instance with different configuration","text":"<p>api2 = MobilityAPI(data_dir=\"data/provider2\")</p>"},{"location":"api-reference/client/#mobility_db_api.api.MobilityAPI-attributes","title":"Attributes","text":""},{"location":"api-reference/client/#mobility_db_api.api.MobilityAPI.base_url","title":"<code>base_url = 'https://api.mobilitydatabase.org/v1'</code>  <code>instance-attribute</code>","text":""},{"location":"api-reference/client/#mobility_db_api.api.MobilityAPI.data_dir","title":"<code>data_dir = Path(data_dir)</code>  <code>instance-attribute</code>","text":""},{"location":"api-reference/client/#mobility_db_api.api.MobilityAPI.logger","title":"<code>logger = setup_logger(name=f'{logger_name}_{data_dir}', level=log_level)</code>  <code>instance-attribute</code>","text":""},{"location":"api-reference/client/#mobility_db_api.api.MobilityAPI.metadata_file","title":"<code>metadata_file = self.data_dir / 'datasets_metadata.json'</code>  <code>instance-attribute</code>","text":""},{"location":"api-reference/client/#mobility_db_api.api.MobilityAPI.refresh_token","title":"<code>refresh_token = refresh_token</code>  <code>instance-attribute</code>","text":""},{"location":"api-reference/client/#mobility_db_api.api.MobilityAPI-functions","title":"Functions","text":""},{"location":"api-reference/client/#mobility_db_api.api.MobilityAPI.delete_all_datasets","title":"<code>delete_all_datasets()</code>","text":"<p>Delete all downloaded datasets. The main data directory is preserved, only dataset directories are removed.</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if all datasets were deleted successfully, False if any deletion failed</p> Source code in <code>src/mobility_db_api/api.py</code> <pre><code>def delete_all_datasets(self) -&gt; bool:\n    \"\"\"\n    Delete all downloaded datasets.\n    The main data directory is preserved, only dataset directories are removed.\n\n    Returns:\n        True if all datasets were deleted successfully, False if any deletion failed\n    \"\"\"\n    if not self.datasets:\n        self.logger.info(\"No datasets to delete\")\n        return True\n\n    success = True\n    provider_dirs = set()\n\n    for key, meta in list(self.datasets.items()):\n        try:\n            if meta.download_path.exists():\n                shutil.rmtree(meta.download_path)\n                self.logger.info(f\"Deleted dataset directory: {meta.download_path}\")\n\n            # Store provider directory for later cleanup\n            provider_dirs.add(meta.download_path.parent)\n\n            # Remove from metadata\n            del self.datasets[key]\n\n        except Exception as e:\n            self.logger.error(f\"Error deleting dataset {key}: {str(e)}\")\n            success = False\n\n    # Save metadata after all deletions\n    if success:\n        self._save_metadata()\n\n        # Clean up empty provider directories\n        for provider_dir in provider_dirs:\n            self._cleanup_empty_provider_dir(provider_dir)\n\n    return success\n</code></pre>"},{"location":"api-reference/client/#mobility_db_api.api.MobilityAPI.delete_dataset","title":"<code>delete_dataset(provider_id, dataset_id=None)</code>","text":"<p>Delete a downloaded dataset.</p> <p>Parameters:</p> Name Type Description Default <code>provider_id</code> <code>str</code> <p>The ID of the provider</p> required <code>dataset_id</code> <code>Optional[str]</code> <p>Optional specific dataset ID. If not provided, deletes the latest dataset</p> <code>None</code> <p>Returns:</p> Type Description <code>bool</code> <p>True if the dataset was deleted, False if it wasn't found or couldn't be deleted</p> Source code in <code>src/mobility_db_api/api.py</code> <pre><code>def delete_dataset(self, provider_id: str, dataset_id: Optional[str] = None) -&gt; bool:\n    \"\"\"\n    Delete a downloaded dataset.\n\n    Args:\n        provider_id: The ID of the provider\n        dataset_id: Optional specific dataset ID. If not provided, deletes the latest dataset\n\n    Returns:\n        True if the dataset was deleted, False if it wasn't found or couldn't be deleted\n    \"\"\"\n    # Find matching datasets\n    matches = [\n        (key, meta) for key, meta in self.datasets.items()\n        if meta.provider_id == provider_id and\n        (dataset_id is None or meta.dataset_id == dataset_id)\n    ]\n\n    if not matches:\n        self.logger.error(f\"No matching dataset found for provider {provider_id}\")\n        return False\n\n    # If dataset_id not specified, take the latest one\n    if dataset_id is None and len(matches) &gt; 1:\n        matches.sort(key=lambda x: x[1].download_date, reverse=True)\n\n    key, meta = matches[0]\n    provider_dir = meta.download_path.parent\n\n    try:\n        if meta.download_path.exists():\n            shutil.rmtree(meta.download_path)\n            self.logger.info(f\"Deleted dataset directory: {meta.download_path}\")\n\n        # Remove from metadata\n        del self.datasets[key]\n        self._save_metadata()\n\n        # Clean up provider directory if empty\n        self._cleanup_empty_provider_dir(provider_dir)\n\n        return True\n\n    except Exception as e:\n        self.logger.error(f\"Error deleting dataset: {str(e)}\")\n        return False\n</code></pre>"},{"location":"api-reference/client/#mobility_db_api.api.MobilityAPI.delete_provider_datasets","title":"<code>delete_provider_datasets(provider_id)</code>","text":"<p>Delete all downloaded datasets for a specific provider.</p> <p>Parameters:</p> Name Type Description Default <code>provider_id</code> <code>str</code> <p>The ID of the provider whose datasets should be deleted</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if all datasets were deleted successfully, False if any deletion failed</p> Source code in <code>src/mobility_db_api/api.py</code> <pre><code>def delete_provider_datasets(self, provider_id: str) -&gt; bool:\n    \"\"\"\n    Delete all downloaded datasets for a specific provider.\n\n    Args:\n        provider_id: The ID of the provider whose datasets should be deleted\n\n    Returns:\n        True if all datasets were deleted successfully, False if any deletion failed\n    \"\"\"\n    # Find all datasets for this provider\n    matches = [\n        (key, meta) for key, meta in self.datasets.items()\n        if meta.provider_id == provider_id\n    ]\n\n    if not matches:\n        self.logger.error(f\"No datasets found for provider {provider_id}\")\n        return False\n\n    success = True\n    provider_dir = None\n\n    for key, meta in matches:\n        try:\n            if meta.download_path.exists():\n                shutil.rmtree(meta.download_path)\n                self.logger.info(f\"Deleted dataset directory: {meta.download_path}\")\n\n            # Store provider directory for later cleanup\n            provider_dir = meta.download_path.parent\n\n            # Remove from metadata\n            del self.datasets[key]\n\n        except Exception as e:\n            self.logger.error(f\"Error deleting dataset {key}: {str(e)}\")\n            success = False\n\n    # Save metadata after all deletions\n    if success:\n        self._save_metadata()\n\n        # Clean up provider directory if empty\n        if provider_dir:\n            self._cleanup_empty_provider_dir(provider_dir)\n\n    return success\n</code></pre>"},{"location":"api-reference/client/#mobility_db_api.api.MobilityAPI.download_latest_dataset","title":"<code>download_latest_dataset(provider_id, download_dir=None, use_direct_source=False)</code>","text":"<p>Download the latest GTFS dataset from a provider.</p> <p>This method handles both hosted and direct source downloads. It includes progress tracking, metadata collection, and automatic extraction of downloaded datasets.</p> <p>Parameters:</p> Name Type Description Default <code>provider_id</code> <code>str</code> <p>The unique identifier of the provider</p> required <code>download_dir</code> <code>Optional[str]</code> <p>Optional custom directory to store the dataset</p> <code>None</code> <code>use_direct_source</code> <code>bool</code> <p>Whether to use direct download URL instead of              hosted dataset. Defaults to False.</p> <code>False</code> <p>Returns:</p> Type Description <code>Optional[Path]</code> <p>Path to the extracted dataset directory if successful, None if download fails.</p> <code>Optional[Path]</code> <p>The directory contains the extracted GTFS files (txt files).</p> Example <p>api = MobilityAPI() dataset_path = api.download_latest_dataset(\"tld-5862\") print(dataset_path) PosixPath('mobility_datasets/volanbus_20240315')</p> Source code in <code>src/mobility_db_api/api.py</code> <pre><code>def download_latest_dataset(self, provider_id: str, download_dir: Optional[str] = None, use_direct_source: bool = False) -&gt; Optional[Path]:\n    \"\"\"Download the latest GTFS dataset from a provider.\n\n    This method handles both hosted and direct source downloads. It includes\n    progress tracking, metadata collection, and automatic extraction of\n    downloaded datasets.\n\n    Args:\n        provider_id: The unique identifier of the provider\n        download_dir: Optional custom directory to store the dataset\n        use_direct_source: Whether to use direct download URL instead of\n                         hosted dataset. Defaults to False.\n\n    Returns:\n        Path to the extracted dataset directory if successful, None if download fails.\n        The directory contains the extracted GTFS files (txt files).\n\n    Example:\n        &gt;&gt;&gt; api = MobilityAPI()\n        &gt;&gt;&gt; dataset_path = api.download_latest_dataset(\"tld-5862\")\n        &gt;&gt;&gt; print(dataset_path)\n        PosixPath('mobility_datasets/volanbus_20240315')\n    \"\"\"\n    try:\n        # Get provider info\n        self.logger.info(f\"Fetching provider info for {provider_id}\")\n        url = f\"{self.base_url}/gtfs_feeds/{provider_id}\"\n        response = requests.get(url, headers=self._get_headers())\n        if response.status_code != 200:\n            self.logger.error(f\"Failed to get provider info: {response.status_code}\")\n            return None\n\n        provider_data = response.json()\n        provider_name = provider_data.get('provider', 'Unknown Provider')\n        latest_dataset = provider_data.get('latest_dataset')\n\n        # For direct source, we don't need latest_dataset\n        if use_direct_source:\n            if not provider_data.get('source_info', {}).get('producer_url'):\n                self.logger.error(\"No direct download URL available for this provider\")\n                return None\n            download_url = provider_data['source_info']['producer_url']\n            api_hash = None\n            is_direct = True\n            # Create a pseudo dataset ID for direct downloads\n            latest_dataset = {\n                'id': f\"direct_{datetime.now().strftime('%Y%m%d%H%M%S')}\"\n            }\n        else:\n            if not latest_dataset:\n                self.logger.error(f\"No latest dataset available for provider {provider_id}\")\n                return None\n            download_url = latest_dataset['hosted_url']\n            api_hash = latest_dataset.get('hash')\n            is_direct = False\n\n        # Create provider directory with sanitized name\n        safe_name = self._sanitize_provider_name(provider_name)\n        base_dir = Path(download_dir) if download_dir else self.data_dir\n        base_dir.mkdir(parents=True, exist_ok=True)\n        provider_dir = base_dir / f\"{provider_id}_{safe_name}\"\n        provider_dir.mkdir(exist_ok=True)\n\n        # Check if we already have this dataset\n        dataset_key = f\"{provider_id}_{latest_dataset['id']}\"\n        old_dataset_id = None\n        old_dataset_path = None\n\n        # Find any existing dataset for this provider\n        for key, meta in list(self.datasets.items()):\n            if meta.provider_id == provider_id:\n                if dataset_key == key and meta.is_direct_source == is_direct:\n                    if api_hash and api_hash == meta.api_provided_hash:\n                        self.logger.info(f\"Dataset {dataset_key} already exists and hash matches\")\n                        return meta.download_path\n                    elif not api_hash and meta.download_path.exists():\n                        # For direct source, download and compare file hash\n                        self.logger.info(\"Checking if direct source dataset has changed...\")\n                        temp_file = provider_dir / f\"temp_{datetime.now().strftime('%Y%m%d_%H%M%S')}.zip\"\n                        start_time = time.time()\n                        response = requests.get(download_url)\n                        download_time = time.time() - start_time\n                        if response.status_code == 200:\n                            with open(temp_file, 'wb') as f:\n                                f.write(response.content)\n                            new_hash = self._calculate_file_hash(temp_file)\n                            if new_hash == meta.file_hash:\n                                temp_file.unlink()\n                                self.logger.info(f\"Dataset {dataset_key} already exists and content matches\")\n                                return meta.download_path\n                            # If hash different, continue with new download\n                            temp_file.unlink()\n                # Store the old dataset info for later cleanup\n                old_dataset_id = meta.dataset_id\n                old_dataset_path = meta.download_path\n                # Remove old dataset from metadata now\n                del self.datasets[key]\n\n        # Download dataset\n        self.logger.info(f\"Downloading dataset from {download_url}\")\n        start_time = time.time()\n        response = requests.get(download_url)\n        download_time = time.time() - start_time\n\n        if response.status_code != 200:\n            self.logger.error(f\"Failed to download dataset: {response.status_code}\")\n            return None\n\n        # Save and process the zip file\n        zip_file = provider_dir / f\"{latest_dataset['id']}.zip\"\n        with open(zip_file, 'wb') as f:\n            f.write(response.content)\n\n        zip_size = zip_file.stat().st_size\n        self.logger.info(f\"Download completed in {download_time:.2f} seconds\")\n        self.logger.info(f\"Downloaded file size: {zip_size / 1024 / 1024:.2f} MB\")\n\n        # Calculate file hash\n        file_hash = self._calculate_file_hash(zip_file)\n\n        # Extract dataset\n        self.logger.info(\"Extracting dataset...\")\n        extract_dir = provider_dir / latest_dataset['id']\n        start_time = time.time()\n        with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n            zip_ref.extractall(extract_dir)\n        extract_time = time.time() - start_time\n\n        extracted_size = self._get_directory_size(extract_dir)\n        self.logger.info(f\"Extraction completed in {extract_time:.2f} seconds\")\n        self.logger.info(f\"Extracted size: {extracted_size / 1024 / 1024:.2f} MB\")\n\n        # Get feed dates from feed_info.txt\n        feed_start_date, feed_end_date = self._get_feed_dates(extract_dir)\n        if feed_start_date and feed_end_date:\n            self.logger.info(f\"Feed validity period: {feed_start_date} to {feed_end_date}\")\n\n        # Clean up zip file\n        self.logger.info(\"Cleaning up downloaded zip file...\")\n        zip_file.unlink()\n\n        # Save metadata\n        metadata = DatasetMetadata(\n            provider_id=provider_id,\n            provider_name=provider_name,\n            dataset_id=latest_dataset['id'],\n            download_date=datetime.now(),\n            source_url=download_url,\n            is_direct_source=is_direct,\n            api_provided_hash=api_hash,\n            file_hash=file_hash,\n            download_path=extract_dir,\n            feed_start_date=feed_start_date,\n            feed_end_date=feed_end_date\n        )\n        self.datasets[dataset_key] = metadata\n        self._save_metadata()  # Save to main metadata file\n        if download_dir:\n            self._save_metadata(base_dir)  # Save to custom directory metadata file\n\n        # Clean up old dataset if it exists\n        if old_dataset_path and old_dataset_path.exists():\n            self.logger.info(f\"Cleaning up old dataset {old_dataset_id}...\")\n            shutil.rmtree(old_dataset_path)\n\n        return extract_dir\n    except requests.exceptions.RequestException as e:\n        self.logger.error(f\"Network error during download: {str(e)}\")\n        return None\n    except (zipfile.BadZipFile, OSError) as e:\n        self.logger.error(f\"Error processing dataset: {str(e)}\")\n        return None\n</code></pre>"},{"location":"api-reference/client/#mobility_db_api.api.MobilityAPI.ensure_metadata_current","title":"<code>ensure_metadata_current()</code>","text":"<p>Ensure the in-memory metadata is current with the file. This is a convenience method that should be called before any operation that reads from the metadata.</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if metadata was reloaded, False if no reload was needed</p> Source code in <code>src/mobility_db_api/api.py</code> <pre><code>def ensure_metadata_current(self) -&gt; bool:\n    \"\"\"\n    Ensure the in-memory metadata is current with the file.\n    This is a convenience method that should be called before\n    any operation that reads from the metadata.\n\n    Returns:\n        bool: True if metadata was reloaded, False if no reload was needed\n    \"\"\"\n    return self.reload_metadata(force=False)\n</code></pre>"},{"location":"api-reference/client/#mobility_db_api.api.MobilityAPI.get_access_token","title":"<code>get_access_token()</code>","text":"<p>Get a valid access token for API authentication.</p> <p>This method handles token refresh automatically when needed. It uses the refresh token to obtain a new access token from the API.</p> <p>Returns:</p> Type Description <code>Optional[str]</code> <p>A valid access token string if successful, None if token refresh fails.</p> Example <p>api = MobilityAPI() token = api.get_access_token() print(token) 'eyJ0eXAiOiJKV1QiLCJhbGc...'</p> Source code in <code>src/mobility_db_api/api.py</code> <pre><code>def get_access_token(self) -&gt; Optional[str]:\n    \"\"\"Get a valid access token for API authentication.\n\n    This method handles token refresh automatically when needed. It uses the\n    refresh token to obtain a new access token from the API.\n\n    Returns:\n        A valid access token string if successful, None if token refresh fails.\n\n    Example:\n        &gt;&gt;&gt; api = MobilityAPI()\n        &gt;&gt;&gt; token = api.get_access_token()\n        &gt;&gt;&gt; print(token)\n        'eyJ0eXAiOiJKV1QiLCJhbGc...'\n    \"\"\"\n    if not self.refresh_token:\n        self.refresh_token = os.getenv(\"MOBILITY_API_REFRESH_TOKEN\")\n    if not self.refresh_token:\n        raise ValueError(\"No refresh token provided and none found in .env file\")\n\n    url = f\"{self.base_url}/tokens\"\n    headers = {\"Content-Type\": \"application/json\"}\n    data = {\"refresh_token\": self.refresh_token}\n\n    try:\n        response = requests.post(url, headers=headers, json=data)\n        if response.status_code == 200:\n            data = response.json()\n            return data.get(\"access_token\")\n        return None\n    except Exception as e:\n        self.logger.error(f\"Exception during token request: {str(e)}\")\n        return None\n</code></pre>"},{"location":"api-reference/client/#mobility_db_api.api.MobilityAPI.get_providers_by_country","title":"<code>get_providers_by_country(country_code)</code>","text":"<p>Search for GTFS providers by country code.</p> <p>Parameters:</p> Name Type Description Default <code>country_code</code> <code>str</code> <p>Two-letter ISO country code (e.g., \"HU\" for Hungary)</p> required <p>Returns:</p> Type Description <code>List[Dict]</code> <p>List of provider dictionaries containing provider information.</p> <code>List[Dict]</code> <p>Each dictionary includes: - id: Provider's unique identifier - provider: Provider's name - country: Provider's country - source_info: Information about data sources</p> Example <p>api = MobilityAPI() providers = api.get_providers_by_country(\"HU\") for p in providers: ...     print(f\"{p['provider']}: {p['id']}\") 'BKK: o-u-dr_bkk'</p> Source code in <code>src/mobility_db_api/api.py</code> <pre><code>def get_providers_by_country(self, country_code: str) -&gt; List[Dict]:\n    \"\"\"Search for GTFS providers by country code.\n\n    Args:\n        country_code: Two-letter ISO country code (e.g., \"HU\" for Hungary)\n\n    Returns:\n        List of provider dictionaries containing provider information.\n        Each dictionary includes:\n            - id: Provider's unique identifier\n            - provider: Provider's name\n            - country: Provider's country\n            - source_info: Information about data sources\n\n    Example:\n        &gt;&gt;&gt; api = MobilityAPI()\n        &gt;&gt;&gt; providers = api.get_providers_by_country(\"HU\")\n        &gt;&gt;&gt; for p in providers:\n        ...     print(f\"{p['provider']}: {p['id']}\")\n        'BKK: o-u-dr_bkk'\n    \"\"\"\n    url = f\"{self.base_url}/gtfs_feeds\"\n    params = {\"country_code\": country_code.upper()}\n\n    try:\n        response = requests.get(url, headers=self._get_headers(), params=params)\n        if response.status_code == 200:\n            return response.json()\n        return []\n    except requests.exceptions.RequestException:\n        return []\n</code></pre>"},{"location":"api-reference/client/#mobility_db_api.api.MobilityAPI.get_providers_by_name","title":"<code>get_providers_by_name(name)</code>","text":"<p>Get providers matching a name (case-insensitive partial match)</p> Source code in <code>src/mobility_db_api/api.py</code> <pre><code>def get_providers_by_name(self, name: str) -&gt; List[Dict]:\n    \"\"\"Get providers matching a name (case-insensitive partial match)\"\"\"\n    url = f\"{self.base_url}/gtfs_feeds\"\n    params = {\"provider\": name}\n\n    response = requests.get(url, headers=self._get_headers(), params=params)\n    if response.status_code == 200:\n        return response.json()\n    return []\n</code></pre>"},{"location":"api-reference/client/#mobility_db_api.api.MobilityAPI.list_downloaded_datasets","title":"<code>list_downloaded_datasets()</code>","text":"<p>Get a list of all downloaded datasets in the data directory.</p> <p>Returns:</p> Type Description <code>List[DatasetMetadata]</code> <p>List of DatasetMetadata objects for all downloaded datasets</p> Source code in <code>src/mobility_db_api/api.py</code> <pre><code>def list_downloaded_datasets(self) -&gt; List[DatasetMetadata]:\n    \"\"\"\n    Get a list of all downloaded datasets in the data directory.\n\n    Returns:\n        List of DatasetMetadata objects for all downloaded datasets\n    \"\"\"\n    return [meta for meta in self.datasets.values() \n            if meta.download_path.exists()]\n</code></pre>"},{"location":"api-reference/client/#mobility_db_api.api.MobilityAPI.reload_metadata","title":"<code>reload_metadata(force=False)</code>","text":"<p>Reload metadata from file if it has been modified or if forced.</p> <p>Parameters:</p> Name Type Description Default <code>force</code> <code>bool</code> <p>If True, reload metadata regardless of modification time.   If False, only reload if the file has been modified.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>bool</code> <p>True if metadata was reloaded, False if no reload was needed</p> Source code in <code>src/mobility_db_api/api.py</code> <pre><code>def reload_metadata(self, force: bool = False):\n    \"\"\"\n    Reload metadata from file if it has been modified or if forced.\n\n    Args:\n        force: If True, reload metadata regardless of modification time.\n              If False, only reload if the file has been modified.\n\n    Returns:\n        bool: True if metadata was reloaded, False if no reload was needed\n    \"\"\"\n    if force or self._has_metadata_changed():\n        self._load_metadata()\n        return True\n    return False\n</code></pre>"},{"location":"api-reference/client/#common-exceptions","title":"Common Exceptions","text":"<p>The client can raise the following exceptions:</p>"},{"location":"api-reference/client/#valueerror","title":"ValueError","text":"<p>Raised in cases like: - Missing or invalid refresh token - Failed token refresh - Invalid provider ID</p>"},{"location":"api-reference/client/#requestsexceptionsrequestexception","title":"requests.exceptions.RequestException","text":"<p>Raised for network-related issues: - Connection errors - API errors - Timeout issues</p>"},{"location":"api-reference/client/#oserror","title":"OSError","text":"<p>Raised for file system issues: - Permission errors - Disk space issues - File access problems</p>"},{"location":"api-reference/client/#environment-variables","title":"Environment Variables","text":"<p>The following environment variables can be used to configure the client:</p> <ul> <li><code>MOBILITY_API_REFRESH_TOKEN</code>: The API refresh token for authentication</li> <li><code>MOBILITY_API_BASE_URL</code>: The base URL of the Mobility Database API</li> <li><code>MOBILITY_API_DATA_DIR</code>: The default directory for storing downloaded datasets</li> </ul>"},{"location":"api-reference/client/#type-hints","title":"Type Hints","text":"<pre><code>from typing import Dict, List, Optional, Union\nfrom pathlib import Path\nfrom datetime import datetime\nfrom dataclasses import dataclass\n\n@dataclass\nclass DatasetMetadata:\n    provider_id: str\n    provider_name: str\n    dataset_id: str\n    download_date: datetime\n    source_url: str\n    is_direct_source: bool\n    api_provided_hash: Optional[str]\n    file_hash: str\n    download_path: Path\n    feed_start_date: Optional[str] = None\n    feed_end_date: Optional[str] = None\n\n# Function signatures\ndef get_providers_by_country(country_code: str) -&gt; List[Dict]: ...\ndef get_providers_by_name(name: str) -&gt; List[Dict]: ...\ndef download_latest_dataset(\n    provider_id: str,\n    download_dir: Optional[str] = None,\n    use_direct_source: bool = False\n) -&gt; Optional[Path]: ...\ndef list_downloaded_datasets() -&gt; List[DatasetMetadata]: ...\ndef delete_dataset(provider_id: str, dataset_id: Optional[str] = None) -&gt; bool: ...\ndef delete_provider_datasets(provider_id: str) -&gt; bool: ...\ndef delete_all_datasets() -&gt; bool: ...\n</code></pre>"},{"location":"api-reference/client/#usage-examples","title":"Usage Examples","text":""},{"location":"api-reference/client/#basic-usage","title":"Basic Usage","text":"<pre><code>from mobility_db_api import MobilityAPI\n\n# Initialize client\napi = MobilityAPI()\n\n# Search for providers\nproviders = api.get_providers_by_country(\"BE\")\nfor provider in providers:\n    print(f\"Found provider: {provider['provider']}\")\n\n# Download dataset\ndataset_path = api.download_latest_dataset(providers[0]['id'])\nprint(f\"Dataset downloaded to: {dataset_path}\")\n</code></pre>"},{"location":"api-reference/client/#dataset-management","title":"Dataset Management","text":"<pre><code>from mobility_db_api import MobilityAPI\n\napi = MobilityAPI()\n\n# List downloaded datasets\ndatasets = api.list_downloaded_datasets()\nfor dataset in datasets:\n    print(f\"Dataset: {dataset.dataset_id}\")\n    print(f\"Provider: {dataset.provider_name}\")\n    print(f\"Downloaded: {dataset.download_date}\")\n\n# Delete specific dataset\napi.delete_dataset(\"tld-5862\", \"20240315\")\n\n# Delete all datasets for a provider\napi.delete_provider_datasets(\"tld-5862\")\n\n# Delete all datasets\napi.delete_all_datasets()\n</code></pre>"},{"location":"api-reference/client/#error-handling","title":"Error Handling","text":"<pre><code>from mobility_db_api import MobilityAPI\nimport requests\n\napi = MobilityAPI()\n\ntry:\n    dataset_path = api.download_latest_dataset(\"invalid-id\")\nexcept ValueError as e:\n    print(f\"Invalid input: {e}\")\nexcept requests.exceptions.RequestException as e:\n    print(f\"Network error: {e}\")\nexcept OSError as e:\n    print(f\"File system error: {e}\")\n</code></pre>"},{"location":"api-reference/client/#implementation-details","title":"Implementation Details","text":""},{"location":"api-reference/client/#authentication-flow","title":"Authentication Flow","text":"<ol> <li>Initialize client with refresh token</li> <li>Client automatically handles token refresh</li> <li>Access token is used for API requests</li> <li>Refresh token is used to obtain new access tokens</li> </ol>"},{"location":"api-reference/client/#download-process","title":"Download Process","text":"<ol> <li>Get provider information</li> <li>Choose download source (hosted or direct)</li> <li>Download dataset to specified directory</li> <li>Update metadata with download information</li> <li>Return path to downloaded dataset</li> </ol>"},{"location":"api-reference/client/#metadata-management","title":"Metadata Management","text":"<ol> <li>Each download directory has its own metadata file</li> <li>Metadata is locked during updates</li> <li>Changes are detected using checksums</li> <li>Failed downloads are cleaned up </li> </ol>"},{"location":"api-reference/metadata/","title":"API Reference: Metadata","text":""},{"location":"api-reference/metadata/#metadata-structure","title":"Metadata Structure","text":"<p>The metadata is stored in JSON format with the following structure:</p> <pre><code>{\n    \"dataset_id\": {\n        \"provider_id\": \"string\",\n        \"provider_name\": \"string\",\n        \"dataset_id\": \"string\",\n        \"download_date\": \"string (ISO format)\",\n        \"source_url\": \"string\",\n        \"is_direct_source\": \"boolean\",\n        \"api_provided_hash\": \"string (optional)\",\n        \"file_hash\": \"string (SHA-256)\",\n        \"download_path\": \"string (relative path)\",\n        \"feed_start_date\": \"string (optional)\",\n        \"feed_end_date\": \"string (optional)\"\n    }\n}\n</code></pre>"},{"location":"api-reference/metadata/#datasetmetadata-class","title":"DatasetMetadata Class","text":"<pre><code>@dataclass\nclass DatasetMetadata:\n    \"\"\"Metadata for a downloaded GTFS dataset\"\"\"\n    provider_id: str\n    provider_name: str\n    dataset_id: str\n    download_date: datetime\n    source_url: str\n    is_direct_source: bool\n    api_provided_hash: Optional[str]\n    file_hash: str\n    download_path: Path\n    feed_start_date: Optional[str] = None\n    feed_end_date: Optional[str] = None\n</code></pre>"},{"location":"api-reference/metadata/#metadatalock-class","title":"MetadataLock Class","text":"<pre><code>class MetadataLock:\n    \"\"\"Context manager for safely reading/writing metadata file\"\"\"\n    def __init__(self, metadata_file: Path, mode: str):\n        self.file = open(metadata_file, mode)\n        self.mode = mode\n\n    def __enter__(self):\n        # Use exclusive lock for writing, shared lock for reading\n        fcntl.flock(self.file.fileno(), \n                   fcntl.LOCK_EX if 'w' in self.mode else fcntl.LOCK_SH)\n        return self.file\n\n    def __exit__(self, exc_type, exc_val, exc_tb):\n        fcntl.flock(self.file.fileno(), fcntl.LOCK_UN)\n        self.file.close()\n</code></pre>"},{"location":"api-reference/metadata/#usage-examples","title":"Usage Examples","text":""},{"location":"api-reference/metadata/#reading-metadata","title":"Reading Metadata","text":"<pre><code>from mobility_db_api import MobilityAPI\n\napi = MobilityAPI()\n\n# List all downloaded datasets\ndatasets = api.list_downloaded_datasets()\nfor dataset in datasets:\n    print(f\"\\nDataset: {dataset.dataset_id}\")\n    print(f\"Provider: {dataset.provider_name}\")\n    print(f\"Downloaded: {dataset.download_date}\")\n    print(f\"Path: {dataset.download_path}\")\n</code></pre>"},{"location":"api-reference/metadata/#metadata-management","title":"Metadata Management","text":"<pre><code>from mobility_db_api import MobilityAPI\n\napi = MobilityAPI()\n\n# Force metadata reload\napi.reload_metadata(force=True)\n\n# Check if metadata needs reload\nif api.ensure_metadata_current():\n    print(\"Metadata was reloaded\")\nelse:\n    print(\"Metadata is current\")\n</code></pre>"},{"location":"api-reference/metadata/#implementation-details","title":"Implementation Details","text":""},{"location":"api-reference/metadata/#file-structure","title":"File Structure","text":"<ul> <li>Default metadata file: <code>data/datasets_metadata.json</code></li> <li>Each download directory can have its own metadata file</li> <li>Lock files use <code>.lock</code> extension</li> </ul>"},{"location":"api-reference/metadata/#thread-safety","title":"Thread Safety","text":"<p>The metadata handler ensures thread safety through:</p> <ol> <li>File locking during read/write operations:</li> <li>Shared locks for reading (multiple readers allowed)</li> <li>Exclusive locks for writing (one writer at a time)</li> <li>Atomic write operations</li> <li>Lock file cleanup on process exit</li> </ol>"},{"location":"api-reference/metadata/#process-safety","title":"Process Safety","text":"<p>Cross-process safety is achieved by:</p> <ol> <li>Using file system locks (fcntl)</li> <li>Handling stale locks</li> <li>Implementing lock timeouts</li> </ol>"},{"location":"api-reference/metadata/#error-handling","title":"Error Handling","text":"<pre><code>from mobility_db_api import MobilityAPI\nimport json\n\napi = MobilityAPI()\n\ntry:\n    # Force metadata reload\n    api.reload_metadata(force=True)\nexcept json.JSONDecodeError as e:\n    print(f\"Corrupted metadata file: {e}\")\nexcept OSError as e:\n    print(f\"File system error: {e}\")\n</code></pre>"}]}